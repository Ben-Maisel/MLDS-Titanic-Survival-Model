{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1de5b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "output_dir = None\n",
    "data_dir = None\n",
    "\n",
    "output_dir = output_dir or os.getenv(\"OUTPUT_DIR\", \"/app/output_folder\")\n",
    "data_dir   = data_dir   or os.getenv(\"DATA_DIR\",   \"/app/data\")\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91a1425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded libraries\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "print('loaded libraries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dcb34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(f'{data_dir}/train.csv')\n",
    "test  = pd.read_csv(f'{data_dir}/test.csv')\n",
    "test_raw = pd.read_csv(f'{data_dir}/test.csv')  # keep PassengerId safe\n",
    "print('loaded data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f55555c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped ['Cabin', 'PassengerId', 'Name', 'Ticket', 'Embarked'] from data\n",
      "imputed missing \"Age\" values (Method = KNN)\n",
      "dropped any remaining rows with Null values\n"
     ]
    }
   ],
   "source": [
    "drop_cols = ['Cabin', 'PassengerId', 'Name', 'Ticket', 'Embarked']\n",
    "train.drop(columns=drop_cols, inplace=True, errors='ignore')\n",
    "test.drop(columns=drop_cols,  inplace=True, errors='ignore')\n",
    "\n",
    "print(\"dropped ['Cabin', 'PassengerId', 'Name', 'Ticket', 'Embarked'] from data\")\n",
    "\n",
    "num_features = [\"Age\", \"Fare\", \"SibSp\", \"Parch\", \"Pclass\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "imputer = KNNImputer(n_neighbors=5, weights=\"distance\")\n",
    "\n",
    "scaled_train = scaler.fit_transform(train[num_features])\n",
    "imputed_scaled_train = imputer.fit_transform(scaled_train)\n",
    "train[num_features] = scaler.inverse_transform(imputed_scaled_train)\n",
    "\n",
    "scaled_test = scaler.transform(test[num_features])\n",
    "imputed_scaled_test = imputer.transform(scaled_test)\n",
    "test[num_features] = scaler.inverse_transform(imputed_scaled_test)\n",
    "\n",
    "print('imputed missing \"Age\" values (Method = KNN)')\n",
    "\n",
    "train.dropna(subset=num_features + ['Sex', 'Survived'], inplace=True)\n",
    "\n",
    "print('dropped any remaining rows with Null values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c901be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partitioned data into \"X_train\", \"y_train\", \"X_test\"\n"
     ]
    }
   ],
   "source": [
    "y_train = train['Survived']\n",
    "X_train = train[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']]\n",
    "X_test  = test[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']]\n",
    "\n",
    "X_train = pd.get_dummies(X_train, drop_first=True)\n",
    "X_test  = pd.get_dummies(X_test,  drop_first=True)\n",
    "X_test  = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "print('partitioned data into \"X_train\", \"y_train\", \"X_test\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a1ddbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained model and used stratified 5-fold cross validation to evaluate\n",
      "CV Accuracy: 0.801 ± 0.024\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=2000, solver=\"lbfgs\")\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "acc = cross_val_score(clf, X_train, y_train, cv=cv, scoring=\"accuracy\")\n",
    "print(\"trained model and used stratified 5-fold cross validation to evaluate\")\n",
    "print(f\"CV Accuracy: {acc.mean():.3f} ± {acc.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167f3b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitted model and predicted on X_test\n",
      "predictions.csv saved to outputs/predictions_python.csv\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('fitted model and predicted on X_test')\n",
    "\n",
    "predictions = pd.DataFrame({\n",
    "    \"PassengerId\": test_raw[\"PassengerId\"].values,\n",
    "    \"Survived\": y_pred\n",
    "})\n",
    "out_path = os.path.join(output_dir, \"predictions_python.csv\")\n",
    "predictions.to_csv(out_path, index=False)\n",
    "print(f\"predictions saved to {out_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
